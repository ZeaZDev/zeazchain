# Enterprise Observability (The O11y Stack)

If it is not monitored, it is not production. This document defines the "Three Pillars" of Observability required for our distributed K8s/Kafka architecture.

## 1. Metrics (The "What" - Is it broken?)

* **Technology:** **Prometheus** (scraping) & **Grafana** (dashboards).
* **Source:** Prometheus scrapes metrics from:
    * **K8s API Server:** Cluster health, node status, pod restarts, CPU/Mem usage.
    * **NestJS API:** A `/metrics` endpoint (via `prom-client`) MUST expose:
        * API Latency (p95, p99) per endpoint.
        * Error Rates (4xx/5xx) per endpoint.
        * Request Volume (RPS).
    * **Kafka:** Broker health, topic size, and **critical: Consumer Lag**.
    * **RDS:** Database connections, query throughput, CPU/Disk utilization.
* **Dashboards:** Grafana provides a "Single Pane of Glass" for API Health, K8s Cluster State, Kafka Throughput, and FinTech Partner API health.

## 2. Logging (The "Why" - What went wrong?)

* **Technology:** **Grafana Loki** (preferred) or **ELK Stack** (Elasticsearch, Logstash, Kibana).
* **Flow:**
    1.  All services (NestJS pods) MUST log structured JSON to `stdout`. Logs must *not* be written to files.
    2.  A cluster-level agent (Promtail/Fluentd) collects these logs.
    3.  The agent forwards logs to Loki for centralized indexing.
* **Purpose:** Allows engineers to search and filter logs from all 50+ scaled API pods in one place, correlating them by `trace-id`.

## 3. Tracing (The "Where" - Where is the bottleneck?)

* **Technology:** **Jaeger** or **OpenTelemetry (OTel)**.
* **Mandate:** Tracing is non-negotiable for debugging an asynchronous (Kafka) architecture.
* **Flow:**
    1.  The NestJS API is instrumented with OpenTelemetry.
    2.  When a request hits `POST /game/slots/play`, a unique `trace-id` is generated by the Ingress or API.
    3.  This `trace-id` MUST be:
        * Passed in the API response headers.
        * Included in all structured JSON logs for that request.
        * **Injected as a Header into the Kafka message.**
    4.  The `game-consumer` service extracts the `trace-id` from the Kafka message header.
    5.  The consumer includes this `trace-id` in its own logs and database calls.
* **Purpose:** Allows tracing a *single request* across its entire lifecycle: `API-Ingress` ➜ `game-service` ➜ `Kafka Queue` ➜ `game-consumer` ➜ `Postgres Write`.

## 4. Alerting (The "Action" - Wake someone up)

* **Technology:** **Alertmanager** (Prometheus) ➜ **PagerDuty**.
* **Mandatory Alerts (SLOs):** These alerts are based on Service Level Objectives (SLOs) and trigger the Incident Response Runbook.
    * `P0: API_ERROR_RATE > 5%` (5xx errors over 5m) - System is down.
    * `P1: API_LATENCY_P99 > 2s` (API is unacceptably slow).
    * `P1: KAFKA_CONSUMER_LAG > 1000` (Consumers are stuck or failing. Rewards/Game results are not being processed).
    * `P2: FINTECH_API_ERROR_RATE > 10%` (3rd party bank API is down).
    * `P3: CERT_EXPIRY < 30d` (SSL Certificates).
    * `P3: K8S_NODE_CPU_HIGH > 90%` (Cluster scaling required).